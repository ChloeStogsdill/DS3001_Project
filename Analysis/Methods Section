Methods Section

  We decided to use a dataset from Kaggle, TREC_06, that included information regarding around 
15,000 phishing emails. Each observation is a single email, with each email also represented as a row 
that contains relevant information such as body text, subject line, sender, presence of URLs, and 
timestamp. Our target binary variable is whether an email is labeled as phishing (1) or not (0), 
so this study will use supervised learning. While this variable is technically numeric, the goal
is to classify emails as either phishing or not, so we will create a classification models rather than
regression models. 
  We will experiment with models including Logistic Regression, Random Forest Classifier, and SVM with
TF-IDF Vectorization--each of which serves a different purpose. Logistic Regression is a simple
classification approach that will estable a baseline for prediction performance. Random Forest 
Classifier can handle structured features like presence of URLs, email length, and sender frequency
while simultaneously reducing overfitting. SVM with TF-IDF Vectorization allows us to extract textural
patterns from email bodies using Term Frequency-Inverse Document Frequency (TF-IDF) to convert text 
into numerical features, like the email body, subject line, and URLs, and then use SVM to analyze 
those textural features. This aids in capturing the importance of specific words within the context of 
the email while reducing the impact of more common words including "and", "in", and "the". 
  We anticipate that extracting those meaningful features from text will be difficult, however we plan
on experimenting with different NLP techniques such as stemming, lemmatization, and n-grams.
Furthermore, the data may require additional cleaning to fix inconsistent timestamps, missing values,
or encoding errors in emails.
  We will evaluate our approach depending on whether the model achieves high predictive accuracy without
significant overfitting. Success of the model was measured through accuracy (overall classification 
correctness), precision and recall (missed phishing email classifications), F1 score (balance 
between precision and recall), and ROC-AUC score (measure of overall classifier performance).
Precision and recall is a particularly important for phishing detection since false negatives are 
riskier than false positives, as these emails can contain potentially dangerous links that steal
pertinent receiver information. Overall, visualizations and feature importance analysis will
provide a deeper understanding of how our model works.
